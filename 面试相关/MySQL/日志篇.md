
## MySQL有哪几种日志？
- undo log 回滚日志 ，实现了事务的原子性，用于实物回滚和MVCC
- redo log 重做日志，实现了事务中的持久性，用于掉电恢复
- bin log (sever层) 归档日志，是Sever层的日志，用于主从复制和数据备份
## undo log有什么作用？
1. 用于事务回滚：在进行增改查操作时，MySQL会隐式的开启一个事务，这个事务在执行阶段会将执行的操作写入undolog，当事务异常，进行回滚操作时，就会读取undo log中的记录，恢复数据
2. 用于MVCC:在实现MVCC过程中，配合ReadView，通过每行记录的隐藏列poll stp 创建版本链，可以进行让事务读取记录行的历史版本，实现可重复读隔离机制
## redo log有什么用？
redo log 是InnoDB 实现崩溃安全和事务回滚的核心机制，它记录物理日志，遵循WAL原则设计
1. 保证事务的持久性：当一个事务提交之后，他会记录下redo log，并不会直接把bufferpool中的脏页刷盘，在满足redolog的刷盘条件时，将redo log写入磁盘，实现数据的一致性，这样即使脏页数据没有持久化，通过redo log 日志也可可以实现数据持久化
2. 崩溃安全：当数据库异常重启时，InnoDB会进入恢复阶段，通过重放redo log ，将buffer pool中的数据数据页恢复至崩溃前的状态，保证了数据的完整性。
3. 提升写性能：redo log 采用顺序追加写的方式写入固定大小的循环文件，相比于更新分散在各处的数据页,相当于随机写，显著提高了I/O性能，提高了高并发能力
### redo log 存储在哪里，什么时候会刷盘？
- redo log最终会持久化在硬盘里，在此之前，他会先被保存在 redo log buffer 中。在磁盘中，默认为redo log file文件，默认为两个，他们是循环写入，覆盖操作的，当写入到文件末尾时会从头继续写，前提条件是旧日志的脏页数据已经刷盘，即已经完成check point
- 事务提交时会刷盘：通过参数控制程度`innodb_flush_log_at_trx_commit`
	- 如果参数为0：事务提交时redo log 留在buffer中，不会主动刷盘，每隔一秒，通过write()写入到page cache中，再调用fsyn()持久化到磁盘
	- 如果参数为1：每次事务提交都会把redo buffer 中的数据写入OS的page cache并且调用fsyn()写入磁盘
	- 如果参数为2：每次事务提交只会把redo buffer 中的数据写入OS的page cache ，等待OS执行刷盘操作，每隔一秒操作一次
- 当redo log buffer 内存使用超过一半时，会执行刷盘操作
- 后台定期刷盘：也有参数控制刷盘程度
	- 
### redo log 文件写满了怎么办？
- 执行check point 时，会触发日志的持久化以释放空间，具体来说解释将buffer pool 中的脏页数据刷入磁盘变成干净页，然后标记哪些redo log 可以擦除，移动check point 
## bin log 有什么用？
bin log 是MySQL sever 层的日志，主要被用来做备份数据和主从复制，他和redo log 有以下不同
1. 适用对象不同
2. 文件格式不同
	1. redo log 记录是物理日志，记录在某个数据页做了什么修改
	2. binlog有三种日志类型
		1. STATEMENT类型：只记录逻辑操作的SQL语句，但可能因为函数操作导致主从不一致
		2. ROW类型：记录行数据最终被修改成什么样子，可能导致binlog体积过大
		3. MIXED类型：根据情况选择SATTATEMENT和ROW类型
3. 写入方式不同
	1. redo log 循环写，不会保存所有操作
	2. bin log 追加写，写满一个文件创建新的文件继续写，保存全量的日志
4. 用途不同
	1. redo log 用于崩溃恢复和事务回滚
	2. bin log 用于主从复制和备份恢复
### 主从复制如何实现？
写入binlog
同步binlog
回放binlog
完成主从复制就可以让主库进行写操作，从库进行读操作
### 从库是不是越多越好？
从库越多会有更多的I/O线程连接到主库，主库为了满足请求，就需要创建更多的log dump线程来处理复制的请求，对主库的资源消耗比较多，同时还受限于主库的网络带宽
### bin log 什么时候刷盘？
事务提交的时候，执行器把binlog cache 里的完整数据写入到binlog文件中，并且清空page cache
## 为什么需要两次提交
两份日志逻辑不一致，导致主从数据不一致
### 两次提交过程是什么样的？
- **prepare 阶段**：将 XID（内部 XA 事务的 ID）写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；
- **commit 阶段**：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；
### 异常重启会出现什么效果？
不管是时刻 A（redo log 已经写入磁盘，binlog 还没写入磁盘），还是时刻 B（redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，此时的 redo log 都处于 prepare 状态。

在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：

- 如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况。
- 如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况。

可以看到，对于处于 prepare 阶段的 redo log，既可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。

所以说，两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID
### 两阶段提交会有什么问题？
1. 磁盘I/O次数高
2. 锁竞争激烈
为了解决I/O问题，发明了组提交
- flush支持redolog组提交
- sync支持binlog组提交
- commit阶段完成最后的引擎提交
## MySQL磁盘I/O很高，有什么优化方法？
现在我们知道事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来“延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率：

- 设置组提交的两个参数：`binlog_group_commit_sync_delay` 和 `binlog_group_commit_sync_no_delay_count` 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。
- 将 `sync_binlog` 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。
- 将 `innodb_flush_log_at_trx_commit` 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「redo log 文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据


